\documentclass{scrartcl}

\title{A1 - HMM}
\subtitle{Artificial Intelligence}
\author{Franco Ruggeri}
\setlength{\parindent}{0pt}

\usepackage{amsmath}
\usepackage[backend=biber]{biblatex}

\bibliography{bibliography.bib}

\DeclareMathOperator*{\argmax}{arg\,max}


\begin{document}
\maketitle

\section{Grade E-D}

\subsection{Question 1}

\begin{equation}
 \mathbf{A} = 
 \begin{bmatrix}
  0.5 & 0.5 \\
  0.5 & 0.5
 \end{bmatrix} 
 ,\ \ \mathbf{B} = 
 \begin{bmatrix}
  0.1 & 0.9 \\
  0.5 & 0.5
 \end{bmatrix} 
 ,\ \ \pi = 
 \begin{bmatrix}
  0.5 & 0.5
 \end{bmatrix} 
\end{equation}

\subsection{Question 2}

\begin{equation}
 P(X_6)\ \mathbf{A} = P(X_7)
\end{equation}
 
\subsection{Question 3}

\begin{equation}
 P(X_7)\ \mathbf{B} = P(O_7)
\end{equation}

\subsection{Question 4}

\begin{align}
 P(O_{1:t}=o_{1:t}, X_t=x_i) &= P(O_t=o_t, O_{1:t-1}=o_{1:t-1}, X_t=x_i) \nonumber \\
 &= \{product\ rule\} \nonumber \\
 &= P(O_t=o_t | X_t=x_i, O_{1:t-1}=o_{1:t-1})\ P(X_t=x_i, O_{1:t-1}=o_{1:t-1}) \nonumber \\
 &= \{conditional\ independence\} \nonumber \\
 &= P(O_t=o_t | X_t=x_i)\ P(X_t=x_i, O_{1:t-1}=o_{1:t-1})
\end{align}

\subsection{Question 5}

\begin{itemize}
 \item $\delta$ has $TxN$ elements
 \item $\delta^idx$ has $(T-1)xN$ elements (no predecessor for $t=0$)
\end{itemize}

\subsection{Question 6}

\begin{align} \label{eq:q6}
 P(X_t=x_i, X_{t+1}=x_j | O_{1:T}=o_{1:T}) &= \{definition\ of\ conditional\ probability\} \nonumber \\
 &= \frac{P(X_t=x_i, X_{t+1}=x_j, O_{1:T}=o_{1:T})}{P(O_{1:T}=o_{1:T})}
\end{align}
The denominator of (\ref{eq:q6}) can be computed using the forward algorithm as $\sum_{k=1}^N \alpha_T(k)$. This term represents a normalization factor.


\section{Grade C}

\subsection{Question 7}

According to \cite{rabiner1989tutorial}, a possible distance measure between two HMMs is:
\begin{equation}
 D(\lambda_1, \lambda_2) = \frac{1}{T} \left[ \log P(O_{1:T}|\lambda_1) - \log P(O_{1:T}|\lambda_2) \right]
\end{equation}
It can be used to define the convergence of the algorithm; that is, if the distance between the result of Baum-Welch algorithm and the generating HMM is little, the algorithm has converged. \\

With 1000 observations:
\begin{equation}
 \mathbf{A} = 
 \begin{bmatrix}
  0.7 & 0.1 & 0.29 \\
  0.1 & 0.81 & 0.09 \\
  0.19 & 0.3 & 0.51
 \end{bmatrix} 
 ,\ \ \mathbf{B} = 
 \begin{bmatrix}
  0.69 & 0.23 & 0.08 & 0.01 \\
  0.07 & 0.41 & 0.28 & 0.24 \\
  0 & 0 & 0.35 & 0.65
 \end{bmatrix}
 ,\ \ D(\lambda_1, \lambda_2) \approx 0.00592
\end{equation}

With 10000 observations:
\begin{equation}
 \mathbf{A} = 
 \begin{bmatrix}
  0.69 & 0.04 & 0.26 \\
  0.12 & 0.75 & 0.14 \\
  0.15 & 0.26 & 0.59
 \end{bmatrix}
 ,\ \ \mathbf{B} = 
 \begin{bmatrix}
  0.71 & 0.19 & 0.1 & 0 \\
  0.1 & 0.42 & 0.31 & 0.17 \\
  0.03 & 0.17 & 0.19 & 0.61
 \end{bmatrix}
 ,\ \ D(\lambda_1, \lambda_2) \approx 0.00079
\end{equation}
As we can see, more observations give a better convergence.

\subsection{Question 8}

Assuming no prior knowledge, a good initialization is:
\begin{equation}
 a_{ij} \approx 1/N,\ \ b_{ij} \approx 1/K,\ \ \pi_i \approx 1/N
\end{equation}
Because, being in the middle, it is more probable to reach the global maximum instead of getting stuck in a local one. \\

So, using this initialization the result after learning with 1000 observations is:
\begin{equation}
  \mathbf{A} = 
 \begin{bmatrix}
  0.7 & 0.29 & 0.01 \\
  0.19 & 0.51 & 0.3 \\
  0.1 & 0.09 & 0.81
 \end{bmatrix} 
 ,\ \ \mathbf{B} = 
 \begin{bmatrix}
  0.69 & 0.23 & 0.08 & 0.01 \\
  0 & 0 & 0.35 & 0.65 \\
  0.07 & 0.41 & 0.28 & 0.24
 \end{bmatrix} 
 ,\ \ D(\lambda_1, \lambda_2) \approx 0.00592
\end{equation}
that is exactly the same obtained in question 7 with the initialization close to the generating model. \\

We can notice that the states 2 and 3 are swapped (i.e. $X_2$ of the learned model is $X_3$ of the generating one and vice versa). This is a problem if we want to compute an element-by-element distance (e.g. Euclidean distance), but if we use the distance measure defined in question 7 it does not matter.

\subsection{Question 9}

More hidden states require more observations, as the Baum-Welch algorithm is based on statistics on how frequent transitions/emissions are and more parameters require more data to have significant statistics. \\

5 states:
\begin{equation}
  \mathbf{A} = 
 \begin{bmatrix}
  0.47 & 0.22 & 0.31 & 0 & 0 \\
  0 & 0.46 & 0 & 0.37 & 0.17 \\
  0 & 0.17 & 0.45 & 0.16 & 0.21 \\
  0.32 & 0 & 0.01 & 0.66 & 0 \\
  0 & 0 & 0.29 & 0 & 0.7
 \end{bmatrix} 
 ,\ \ \mathbf{B} = 
 \begin{bmatrix}
  0.43 & 0.57 & 0 & 0 \\
  0 & 0.4 & 0.6 & 0 \\
  0 & 0 & 0.32 & 0.68 \\
  0 & 0.24 & 0.28 & 0.48 \\
  0.75 & 0.19 & 0.06 & 0
 \end{bmatrix} 
 ,\ \ D(\lambda_1, \lambda_2) \approx 0.016819
\end{equation}

\subsection{Question 10}

Initializing with (exact) uniform distribution, the Baum-Welch algorithm produces:
\begin{equation}
  \mathbf{A} = 
 \begin{bmatrix}
  0.33 & 0.33 & 0.33 \\
  0.33 & 0.33 & 0.33 \\
  0.33 & 0.33 & 0.33 \\
 \end{bmatrix} 
 ,\ \ \mathbf{B} = 
 \begin{bmatrix}
  0.24 & 0.25 & 0.24 & 0.27 \\
  0.24 & 0.25 & 0.24 & 0.27 \\
  0.24 & 0.25 & 0.24 & 0.27 \\
 \end{bmatrix}
\end{equation}
As you can see, the algorithm gets stuck in the initial point, that is a local maximum. Indeed, if the initial $\mathbf{B}$ is uniform, the observations give no information. \\

Initializing with a diagonal $\mathbf{A}$ matrix and $\pi = \left[0,0,1\right]$, we get:
\begin{equation}
  \mathbf{A} = 
 \begin{bmatrix}
  NaN & NaN & NaN \\
  NaN & NaN & NaN \\
  NaN & NaN & NaN \\
 \end{bmatrix} 
 ,\ \ \mathbf{B} = 
 \begin{bmatrix}
  NaN & NaN & NaN & NaN \\
  NaN & NaN & NaN & NaN \\
  NaN & NaN & NaN & NaN \\
 \end{bmatrix}
\end{equation}

Finally, initializing the matrices close to the solution guarantees a good convergence, since the global maximum is reached.


\section{Grade B-A}

\subsection{Shooting}

The most likely next move for one single bird is computed as:
\begin{align}
 next\ move &= \argmax_{m} P(O_{T+1}=o_m | O_{1:T}) \nonumber \\
 &= \sum_{i=1}^N P(O_{T+1} | X_{T+1}=x_i)\ P(X_{T+1}=x_i | O_{1:T}) \nonumber \\
 &= \sum_{i=1}^N b_i(O_{T+1})\ P(X_{T+1}=x_i | O_{1:T}) \nonumber \\
\end{align}

Let's compute $P(X_{T+1}=x_i | O_{1:T})$:
\begin{align}
 P(X_{T+1}=x_i | O_{1:T}) &= \sum_{j=1}^N P(X_{T+1}=x_i | X_T=x_j)\ P(X_T=x_j | O_{1:T}) \nonumber \\
 &= \sum_{j=1}^N a_{ji}\ \frac{P(X_T=x_j, O_{1:T})}{P(O_1:T)} \nonumber \\
 &= \sum_{j=1}^N a_{ji}\ \frac{\alpha_T(j)}{\sum_{k=1}^N \alpha_T(k)} \\
 &= \sum_{j=1}^N a_{ji}\ \hat{\alpha}_T(j)
\end{align}

So the complete formula is:
\begin{equation}
 next\ move = \argmax_{m} \sum_{i=1}^N b_i(O_{T+1})\ \sum_{j=1}^N a_{ji}\ \hat{\alpha}_T(j)
\end{equation}

The idea is to use not only the model of the current bird, but also the models of all the birds belonging to the guessed species, which would have to behave like the current bird. So, I pick the most likely next move overall. \\

Improvements:
\begin{itemize}
 \item Do not shoot if the guess is unknown or black stork.
 \item Shoot only if $confidence > threshold$ (set to 0.75).
\end{itemize}

\subsection{Guessing}
As for shooting, the idea is to use all the available models of the birds whose species has been revealed. So, I pick the species of the bird whose model maximizes the likelihood of the observation sequence (i.e. evaluation problem solved with $\alpha$-pass, species recognition). \\

Improvements:
\begin{itemize}
 \item First round: guess randomly to get information (actually it is better to guess always one species).
 \item Next rounds: guess randomly when the recognition fails (unknown result) to get information.
\end{itemize}


\clearpage
\newpage
\printbibliography

\end{document}

